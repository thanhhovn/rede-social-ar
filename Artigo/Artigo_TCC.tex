\NeedsTeXFormat{LaTeX2e}
%-----------------------------------------------------------
\documentclass[a4paper,12pt]{monografia}
\usepackage{amsmath,amsthm,amsfonts,amssymb}
\usepackage[mathcal]{eucal}
\usepackage{latexsym}
\usepackage[brazil]{babel}
\usepackage[latin1]{inputenc}
\usepackage{bm}
\usepackage[all]{xy}
\usepackage{graphicx,color}
%\usepackage[pdftex]{graphicx}

%-----------------------------------------------------------

%-----------------------------------------------------------
\usepackage{cite}  % pacote para fazer referências usando arquivo .bib
%-----------------------------------------------------------

%-----------------------------------------------------------
\theoremstyle{plain}
\newtheorem{theorem}{Teorema}[section]
\newtheorem{axiom}{Axioma}[section]
\newtheorem{corollary}{Corolário}[section]
\newtheorem{lemma}{Lema}[section]
\newtheorem{proposition}{Proposição}[section]
%-----------------------------------------------------------
\theoremstyle{definition}
\newtheorem{definition}{Definição}[section]
\newtheorem{example}{Exemplo}[section]
%-----------------------------------------------------------
\theoremstyle{remark}
\newtheorem{remark}{Observação}[section]
%-----------------------------------------------------------
%-----------------------------------------------------------
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\id}{\mathbf{1}}
\newcommand{\U}{\mathcal{U}}
\newcommand{\V}{{\cal V}}
%-----------------------------------------------------------
\def\ind{\hbox{ ind }}
%-----------------------------------------------------------
\includeonly{Capt1/AR}
%% Comandos para facilitar a edição 
\newcommand{\cpp}{\texttt{C$++$}}
\newcommand{\latex}{\LaTeX}

%-----------------------------------------------------------

% Parte para inserir código fonte no documento

\usepackage{listings} % para código fonte

% opções do pacote listings
\lstset{numbers=left,
language=python,
stepnumber=1,
firstnumber=1,
numberstyle=\tiny,
extendedchars=true,
breaklines=true,
frame=tb,
basicstyle=\footnotesize,
stringstyle=\ttfamily,
showstringspaces=false
backgroundcolor=\color{gray}
}

\renewcommand{\lstlistingname}{Code}
\renewcommand{\lstlistlistingname}{Lista de Listagens}

\lstset{language=XML} 

%-----------------------------------------------------------

\begin{document}
%
%----------------- Título e Dados do Autor -----------------
\titulo{Rede Social usando Realidade Aumentada}
%\subtitulo{- Fazendo uso da classe MONOGRAFIA -} % opcional
\autor{Lucas Fernandes de Almeida} \nome{Lucas} \ultimonome{Almeida}
%
%---------- Informe o Curso e Grau -----
\bacharelado \curso{Sistemas de Informação} \ano{2013}
\data{15 de Abril de 2013} % data da aprovação
\cidade{Itabaiana}
%
%----------Informações sobre a Instituição -----------------
\instituicao{Universidade Federal de Sergipe} \sigla{UFS}
\unidadeacademica{Centro de Ciências Exatas e Tecnologia}
%
%-------- Informações obtidas na Biblioteca ----------------
%
\CDU{536.21} \areas{1.Realidade Aumentada  2. Geoprocessamento.}
\npaginas{xx}  % total de páginas do trabalho
%------Nomes do Orientador, 1o. Examinador e 2o. Examinador-
\orientador{Andrés Ignácio Martínez Menéndez }
%
%\coorientador{Nome do Co-orientador} % opcional
%
\examinadorum{André Vinicius Rodrigues Passos Nascimento}
%
\examinadordois{Mai-Ly Vanessa Almeida S. Faro}
%
%\examinadortres{Nome do Examinador 3}
%
%\examinadorquatro{Nome do Examinador 4}
%--------- Títulos do Orientador 1o. e 2o. Examinadores ----
%\ttorientador{Graduado em Ciências da Computação - Unit}
%
%\ttcoorientador{Título do Co-orientador} % se digitado \coorientador
%
%\ttexaminadorum{Título do Examinador 1}
%
%\ttexaminadordois{Título do Examinador 2}
%
%\ttexaminadortres{Título do Examinador 3}
%
%\ttexaminadorquatro{Título do Examinador 4}
%
\maketitle
%----------------------------dedicatória  opcional--------------
\begin{dedicatoria}
\\
\\
\end{dedicatoria}
%--------Digite aqui o seu resumo em Português--------------
\resumo{Resumo} 
% Digite aqui

\noindent Palavras-chaves: RA, Geoprocessamento.
%-----------Digite aqui o seu resumo em Inglês--------------
\resumo{Abstract} 
% Digite aqui

\noindent Keywords: AR, GIS.
%-----------Ou digite aqui o seu resumo em Frances----------
%\resumo{Résumé} C'est un modèle de la monographie dans \LaTeX et
%5utilise la classe monografia.cls, avec le but de aider dans le
%maniement des travaux de conclusion des plusieurs cours de
%l'Université Fédérale de Maranhão.
%-----------------------------------------------------------
\agradecimento{Agradecimentos}

\indent\indent A todos os meus parentes, pelo encorajamento e
apoio.

Ao professor Andrés Menéndez pela orientação, amizade e
principalmente, pela paciência, sem a qual este trabalho não se
realizaria.


Aos professores do Departamento de Sistemas de Informação pelos seus
ensinamentos e aos funcionários do curso, que durante esses anos,
contribuíram de algum modo para o nosso enriquecimento pessoal e
profissional.
\newpage
%---------------------- EPÍGRAFE I (OPCIONAL)--------------
\begin{epigrafe}
``Lembra que o sono é sagrado e alimenta de horizontes o tempo acordado de viver''.\\
\hfill Beto Guedes (Amor de Índio)
\end{epigrafe}
%----Sumário, lista de figura e de tabela ------------
\tableofcontents 
\thispagestyle{empty} %\listoffigures
%\thispagestyle{empty} \listoftables \thispagestyle{empty}
%---------------------
%--------------Início do Conteúdo---------------------------
\pagestyle{ruledheader}
%\chapter{Realidade Aumentada}
\listoffigures
\chapter{Introdução}
\label{Intro:intro}
	\indent \indent
		Com o passar dos anos, nossa sociedade vem demonstrando forte apego a sites de relacionamento, a exemplo do Facebook, Orkut e Google+. Isso devido ao forte interesse que as pessoas têm sobre informações de outras pessoas como, por exemplo, saber onde esta ou esteve, com quem conversou e o que andou fazendo. E, principalmente, devido à facilidade que as redes sociais têm de aproximar as pessoas.

    Todas essas redes sociais têm em comum a forma utilizada para prover a interação entre os usuários, através da troca de mensagens, compartilhamento de fotos, vídeos e músicas. Porém, nenhuma dessas redes sociais oferece ao usuário o serviço de localizar usuários e o uso da Realidade Aumentada~\cite{Azuma_1997}. 

    A Realidade Aumentada~\cite{Haller2007} é uma técnica que permite a sobreposição, em tempo real, de imagens virtuais geradas por computador em um ambiente real. Essa técnica fornece ao usuário uma maneira totalmente diferente de interação enriquecendo o ambiente ao qual ele está inserido com novas informações.
    
	Existem duas formas de interação usando a Realidade aumentada~\cite{Haller2007}, com marcação e sem marcação: 
   \begin{enumerate}
   		\item A interação da Realidade Aumentada~\cite{Haller2007} com marcação exige a utilização de uma câmera, código impresso e um software. A câmera é utilizada pelo software para reconhecer o código impresso. Caso este código tenha associado a ele um elemento virtual, seja uma imagem animada, um jogo. Este elemento será mostrado na superfície que o código foi impresso.
   		
   		 % {pensar no por que não usar a RA com marcador}.
   		
   		\item 	Assim como a Realidade Aumentada~\cite{Haller2007} com marcação, a sem marcação faz o uso de uma câmera e de um software, porém não utiliza código impresso para permitir a interação. Em substituição do código impresso é utilizado informações obtidas a partir de sensores de movimento, orientação, e localização (\textit{GPS -Global Positioning System}) disponíveis em alguns dispositivos. Essas informações serão analisadas pelo software que fará a sobreposição dos elementos virtuais, alinhado ao ambiente real indicado pelas coordenadas fornecidas pelos sensores, e exibidos na tela do dispositivo móvel do usuário.

	\end{enumerate}      			
	
Como já foi mencionado, a Realidade Aumentada permite enriquecer o ambiente real (o que está sendo visualizado pelo usuário no seu dispositivo) com novas informações (informações virtuais). Com isso, em se tratando de dispositivos móveis a Realidade Aumentada tem um vasto campo de aplicabilidade.	Veja algumas aplicações da Realidade Aumentada em ~\cite{MonteLima2007}.

Para este projeto, a Realidade Aumentada terá o papel de permitir a visualização de informações, na tela do dispositivo, sobre outros usuários da rede que estejam próximos, coexistindo o real e o virtual na tela do dispositivo do usuário. E para que isso aconteça os usuários da rede terão sua localização guardada em um banco de dados espacial~\cite{Obe_Hsu_2011} (PostgreSQL~\cite{Postgresql} com a extenção PostGis~\cite{Postgis}). 

O Geoprocessamento em conjunto com a Realidade aumentada (usando a técnica sem marcação), irá permitir que a partir do momento que o usuário passar a câmera do dispositivo móvel (usando as informações obtidas pelos sensores do dispositivo) por um determinado lugar que possua coordenadas (latitude e longitude) de algum usuário da rede, será exibido na tela do dispositivo informações sobre este usuário. Com isso, oferecendo aos usuários desta rede uma maneira totalmente diferente de interação.

	Neste trabalho, abordaremos a criação de uma Rede Social usando técnicas da Realidade Aumentada~\cite{Haller2007}, em específico a técnica sem marcação por permitir obter dados dinâmicos, com o intuito de prover a comunicação e localização entre os usuários dessa rede.

	
\chapter{Realidade Aumentada}
\label{Cap:ar}
\section{Introdução}
	\indent \indent A realidade aumentada (RA) teve seus primeiros passos na década de 60, com o pesquisador Ivan Sutherland, com duas principais contribuições:
	
	\begin{enumerate}
    	\item A escrita de um artigo, vislumbrando a evolução da realidade virtual (RV) e seus reflexos no mundo real ~\cite{Sutherland1963};
    	\item O desenvolvimento de um capacete de visão ótica direta rastreado para visualização de objetos 3D no ambiente real ~\cite{Sutherland1968}.
	\end{enumerate}
	
  	 \indent Entretanto, somente na decada de 80 que surgiu o primeiro projeto de realidade aumentada. Este projeto foi desenvolvido pela Força Aérea Americana e tratava-se de um simulador de cockpit de avião, com visão ótica direta, misturando elementos virtuais com o ambiente físico do usuário ~\cite{MarcosWagnerS.Ribeiro2011}.
  	 
\section{Conceitos e Definições}  	 
	\indent \indent 
	 A RA é caracterizada pela inserção de objetos virtuais no ambiente físico, mostrada ao usuário, em tempo real, com o apoio de algum dispositivo tecnológico, usando a interface do ambiente real, adaptada para visualizar e manipular os objetos reais e virtuais  ~\cite{Tori2006a}. 

	 \indent
	 A RA pode ser aplicada a todos os sentidos humanos ~\cite{Azuma2001} e propocionar ao usuário uma interação segura, sem necessidade de treinamento, uma vez que a RA permite trazer para o seu ambiente real objetos virtuais, incrementando e aumentando a visão que o usuário tem do mundo real ~\cite{Kirner2007}. Para proporcionar essa esperiência ao usuário a RA faz uso de uma câmera, técnicas de Visão Computacional e de Computação Gráfica/RV.
	  	 
	\indent
	Existem várias definições para a RV. Alguns autores tentam listar elementos-chave de RV, tais como imersão (sensação de estar em um ambiente), interatividade e \textit{feedback} sensorial (visual, auditivo e táctil) ~\cite{Sherman2003}. Outros descrevem a RV de forma geral, como uma técnica avançada de interface, na qual o usuário pode navegar e interagir em um ambiente tridimensional gerado por computador, estando completa ou parcialmente presente ou então imerso pela sensação gerada por canais multi-sensoriais, sendo a visão o canal principal ~\cite{Ficheman2006}. 

	\indent Assim como a RV a RA os autores têm várias definições, como podemos ver a seguir:
		
	\begin{citacao}
"Uma variante da RV [...]. As tecnologias de RV submergem completamente ao usuário em um ambiente sintético ou virtual e, enquanto imerso nesse ambiente, o usuário não pode ver o mundo real que o rodeia. Pelo contrário, a RA permite ver o mundo real com objetos virtuais sobrepostos ou integrados nesse mundo real. Desta forma, a RA complementa a realidade ao invez de substituí-la. [...]" ~\cite{Kirner2012}.
	\end{citacao}		
	
	\begin{citacao}
	"A realidade aumentada adiciona um pouco mais de mágica à realidade, criando 
novas maneiras de interagir com o mundo físico e permitindo o acesso a dados extremamente valiosos de uma maneira natural". -David Helgason, CEO da Unity Technologies. %dúvida
	\end{citacao}

	\begin{citacao}
	"A realidade aumentada permite que as pessoas visualizem o espaço virtual como parte integral do mundo físico ao seu redor, fazendo com que o mundo real possa ser acessado efetivamente por cliques e links". - Paul E. Jacobs, presidente e diretor executivo da Qualcomm. %tirar dúvida sobre como referenciar
	\end{citacao}
	
	\indent
	Além disso, \cite{Azuma_1997} define três características fundamentais e distintivas para um sistema ser considerado de RA:
	\begin{enumerate}
		\item Combinar o mundo real com o virtual;
		\item Interagir em tempo real;

	\item Ajustar os objetos virtuais no ambiente 3D.
	\end{enumerate}
	
	\indent
	 A RA traz o conceito de conteúdo visual sobreposto ao visualizar o mundo real através de uma câmera.  
	 
	 \indent
	 Para que a RA seja possível são utilizadas duas técnicas para localização do ambiente real que será usado para projetar o elemento virtual, são elas: com marcação (~\textit{mark}) e sem marcação (~\textit{markless}). Sendo a primeira técnica a mais difundida. Na implementação do projeto foi utilizado a técnica sem marcação. Esta técnica utiliza de dados de posição, orientação, dados georeferenciados para localizar o local que será usado para projetar o elemento virtual. Na figura ~\ref{fig_marcacao} e na figura ~\ref{fig_sem_marcacao} podemos ver exemplos de aplicações usando RA com marcação e sem marcação respectivamente.	 
	\begin{figure}[h]
		\begin{center}
			\includegraphics{Figuras/marcacao.png}
			\caption{Aparência de um museu virtual.}
			\label{fig_marcacao}			
		\end{center}
	\end{figure}

	\begin{figure}[h]
		\begin{center}
			\includegraphics{Figuras/sem_marcador.png} 
			\caption{Sistema de RA com registro do ambiente virtual e real usando GPS (\textit{Global Positioning System}).}
			\label{fig_sem_marcacao}
		\end{center}
	\end{figure}
	
	 \indent
	 A RA é utilizada em muitas soluções desde jogos a mídia e marketing interativo, passando por instruções e módulo de ajuda, a realidade aumentada abre espaço para novos aplicativos e serviços móveis. Indo mais fundo, essa tecnologia deverá ter grande impacto no relacionamento das pessoas, através de novas maneiras de realizar visualização, comunicação e interação com pessoas e informação.  

\section{Tipos de Sistemas de Realidade Aumentada}
	\indent \indent
	A depender do tipo de display utilizado ~\cite{Azuma2001}, seja envolvendo visão ótica ou por vídeo, os sistemas de RA podem ser classificados em quatro tipos.
	
	\begin{enumerate}
		\item Sistema de Visão Ótica Direta;
		\item Sistema de Visão Direta Por Vídeo;
		\item Sistema de Visão Ótica Por Projeção;
		\item Sistema de Visão Por Vídeo Baseado em Monitor.
	\end{enumerate}
	
	O sistema de visão ótica direta necessita do uso de óculos ou capacetes, com lentes que permitam o recebimento direto da imagem real, ao mesmo tempo em que permitam a projeção de imagens virtuais devidamente ajustadas com a cena real nos olhos do usuário. Veja um exemplo desse sistema na figura ~\ref{fig_otico}. 
	\begin{figure}[h]
		\begin{center}			
			\includegraphics{Figuras/fig_3_sistema_otico.png}
			\caption{Diagrama e dispositivo do sistema de visão ótica direta [2].}	 
			\label{fig_otico}			
		\end{center}
	\end{figure}
	
	Por sua vez, o sistema de visão direta por vídeo utiliza capacetes com microcâmeras de vídeo acopladas. A cena real capturada pela microcâmera é misturada com os elementos virtuais gerados por computador e apresentadas diretamente nos olhos do usuário, através de pequenos monitores montados no capacete. Veja um exemplo desse sistema na figura ~\ref{fig_video}.
	\begin{figure}[h]
		\begin{center}
			\includegraphics{Figuras/fig_04_sistema_por_video.png} 
			\caption{Diagrama e dispositivo do sistema de visão direta por vídeo [2].}	 
			\label{fig_video}
		\end{center}
	\end{figure}
	
	O sistema de visão ótica por projeção utiliza superfícies do ambiente real. Nessa superfície são projetadas as imagens dos objetos virtuais, cujo conjunto é apresentado ao usuário que o visualiza sem a necessidade de nenhum equipamento auxiliar. O limitante desse sistema é sua necessidade com superfícies de projeção. Veja um exemplo desse sistema na figura ~\ref{fig_projecao}.
	\begin{figure}[t]
		\begin{center}
			\includegraphics{Figuras/fig_06_sistema_de_projecao.png} 
			\caption{Projeção}
			\label{fig_projecao}
		\end{center}
	\end{figure}

	
	Já o sistema de visão por vídeo baseado em monitor utiliza uma webcam para capturar a cena real. Depois de capturada, a cena real é misturada com os objetos virtuais gerados por computador e apresentada no monitor. O ponto de vista do usuário normalmente é fixo e depende do posicionamento da webcam. Veja um exemplo desse sistema na figura ~\ref{fig_monitor}.
	\begin{figure}[ht]
		\begin{center}
			\includegraphics{Figuras/fig_05_sistema_por_video_baseado_em_monitor.png} 
			\caption{Diagrama e  dispositivo do  sistema  de visão  por  vídeo
baseado em monitor [2].} 
			\label{fig_monitor}
		\end{center}
	\end{figure}
	
	Como a intenção deste projeto é a criação de uma rede social para dispositivos móveis usando a RA, dar-se-á maior destaque para o sistema de visão direta por vídeo baseado em monitor. Isso se deve ao fato dessa técnica não necessitar de nenhum equipamento auxiliar, sendo necessária somente a câmera que será a do próprio dispositivo móvel e de um software específico que fará a análise dos dados recebidos e a sobreposição dos elementos virtuais no ambiente real que será mostrado no ~\textit{display} do dispositivo móvel do usuário.
	
\section{Realidade Aumentada Móvel}
	\indent \indent
	Os dispositivos móveis eram conhecidos por possuir um Hardware limitado com pouca memória e baixo poder de processamento. Essas características inviabilizavam o uso da realidade aumentada nos dispositivos móveis já que a RA demanda de recursos computacionais. 
	
	Porém, com o rápido avanço tecnológico dos dispositivos móveis ao longo dos últimos anos essas restrições da utilização da RA foram sanadas. Hoje, praticamente todo dispositivo móvel dá suporte a aplicações baseadas em RA. Com exceção para, aplicações que exige poder computacional acima da média.  
	\begin{figure}[h]
		\begin{center}
			\includegraphics[scale=1]{Figuras/fig_07_RA_dispostivo_movel.png} 
			\caption{Exemplo de uma aplicação usando a RA em um dispositivo móvel.}
			\label{fig_dMovel1}
		\end{center}
	\end{figure}
	
	Atualmente existem inúmeras aplicações que usam técnicas de realidade aumentada para dispositivos móveis, desde aplicações para localização, área da saúde, marketing, jogos, etc. O limite do uso da RA para atender nossas necessidades vai da imaginação de quem cria a aplicação. Veja na figura ~\ref{fig_dMovel1} um dos exemplos da utilização da RA em dispositivos móveis.
		
\section{Projetos Relacionados}
	\indent \indent
	Serão mostrados, nesta seção, alguns dos projetos relacionados ao uso da Realidade Aumentada em dispositivos móveis.
	
	\subsection{ \textit{Mobile Augmente Reality Applications} (MARA)}
	\indent \indent
		Este projeto desenvolvido pela Nokia é aplicado a celulares que dispõem de GPS, acelerómetro  e bússola. Esses sensores têm o papel de determinar a localização e orientação do telefone. 
		
Tem como objetivo, oferecer as seguintes funcionalidades:Identificar restaurantes, hotéis, pontos turísticos, fornecer links da Web e informações básicas sobre esses objetos na tela do telefone. Além disso, David Murphy, engenheiro da Nokia Research Center, afirma que o sistema também pode ser usado para encontrar os amigos próximos, que têm telefones com GPS e software apropriado. % deve ser referenciado
		
Uma vez que o telefone está em modo de câmera, a aplicação MARA reúne as informações dos três sensores para identificar a localização e orientação do telefone, veja a aplicação na figura ~\ref{fig_Mara} . Em seguida, para determinar qual objeto seria visível para a câmera, o software busca objetos no banco de dados que podem ser carregados no telefone ou podem ser acessados através de uma conexão de rede. Com a visibilidade determinada, o software destaca os objetos e fornece informações extras e hiperlinks, se disponível. % deve ser referenciado
	\begin{figure}[t]
		\begin{center}
			\includegraphics[scale=1]{Figuras/ProjetoNokiaMara.png} 
			\caption{Nesta figura é mostrado o protótipo usando a plataforma Nokia S60, mostrando informações da posição e orientação do telefone através de uma conexão Bluetooth.}
			\label{fig_Mara}
		\end{center}
	\end{figure}	
	
	\subsection{LayAr}
		\indent \indent
	O Layar é uma plataforma móvel que ajuda-lhe a pesquisar e a descobrir informações sobre o mundo à sua volta, apresentando informações digitais no campo de visão do seu dispositivo móvel, através da tecnologia RA, veja um exemplo na figura ~\ref{fig_navegacao}. Layar, foi desenvolvido por uma empresa holandesa de mesmo nome, fundada em 2009 por Raimo van der Klein, Claire Boonstra e Maarten Lens-FitzGerald. E está disponível para as plataformas, Android, Iphone (IOS), Symbian e Blackberry.	
	\begin{figure}[h]
		\begin{center}
			\includegraphics{Figuras/navegacao.png} 
			\caption{Nesta figura mostra uma aplicação desenvolvida pela JWT, usando a plataforma Layar, para uma camanpanha hi-tech, Mazda. A aplicação mostra o caminho para encontrar a concessionária Mazda mais próxima.}
			\label{fig_navegacao}
		\end{center}
	\end{figure}	
	

Para permitir que os usuários visualizem diversos itens na tela do dispositivo usando a RA, foram utilizadas, além da visão computacional, alguns componentes: Câmera, Bússola, GPS e Acelerómetro. Esses componentes são utilizados em conjunto para identificar a localização e orientação do dispositivo móvel. Usando essas informações, é feito uma busca em um banco espacial procurando itens que possuem coordenadas (latitude e longitude) próximas da localização do usuário. Por fim, as várias formas de dados coletadas são colocadas sobre a imagem que esta sendo exibida pela câmera, funcionando como uma camada adicional.
	\begin{figure}[!Hbp]
		\begin{center}
			\includegraphics{Figuras/exbindoVideoApartirDeUmJornal.png} 
			\caption{Nesta figura, ao passar o celular sobre uma página do jornal que contém um código reconhecido pelo sistema, é exibido na tela do celular informações digitais (vídeo).}
			\label{fig_reconhecimentoObjeto}
		\end{center}
	\end{figure}
	
	
O Layar oferece vários tipos de experiências aos usuários, com características interativas e imersivas, como objetos em 3D e animação. Algumas das experiências oferecidas pelo Layar são: jogar games usando como cenário o próprio ambiente (veja na figura ~\ref{fig_jogo}), encontrar locais próximos, incluindo cafés, lojas e outros negócios, bem como locais históricos, monumentos e o reconhecimento de objetos do mundo real mostrando experiências digitais em cima deles permitindo que os usuários interajam com esses objetos, que podem ser encontrados em revistas, jornais, cardápios de restaurantes, cartazes publicitários e livros. Veja um exemplo de visão computacional no uso de reconhecimento de objetos na figura ~\ref{fig_reconhecimentoObjeto}.
	\begin{figure}[hbp]
		\begin{center}
			\includegraphics{Figuras/Jogo.png} 
			\caption{Nesta figura é mostrado um jogo que tem como cena a imagem do próprio ambiente.}
			\label{fig_jogo}
		\end{center}
	\end{figure}	
		
	\subsection{Realidade Urbana Aumentada (RUA)}
	\indent \indent
		Este projeto faz parte de um projeto maior, Wikinarua. O Wikinarua visa à criação de uma rede social como proposta de inclusão artística. O software RUA assim como o Wikinarua foram desenvolvidos na Universidade de Brasília. O RUA Permitindo, o compartilhamento de fotos, vídeos, músicas, comunicação entre os usuários, a visualização de um monumento histórico e suas ruínas em diferentes momentos de sua existência, observar os mínimos detalhes de algumas obras de arte na tela do dispositivo e o reconhecimento de imagens para a identificação de diversos espaços e pontos importantes de cidades de todo o Brasil. 

O Software RUA, faz uso da biblioteca gráfica 3D (OpenGL) para a geração de objetos 3D, da biblioteca ARTollkit (Realidade Aumentada) para o rastreamento de marcadores, acelerômetro, GPS e magnetômetro. O GPS e a bússola (magnetômetro) são usados para identificar onde você está e a direação para qual o celular esta apontando. Este projeto foi inicialmente desenvolvido para a API 3.0 do Iphone, mas será estendido para a plataforma Android.
 
%% Fim de RA

\chapter{Plataforma Android}
\label{android}
	\indent \indent
	Neste capítulo, será apresentada a Plataforma Android, especificando suas principais características, assim como sua infraestrutura, arquitetura e principais recursos.
	
\section{O que é o Android?}
\label{android:oqueE}
\indent \indent
O Android é uma plataforma de desenvolvimento, rica em recursos, voltada para a criação de aplicativos móveis, a exemplo dos smartphones. O Android possui um sistema operacional baseado em Linux, um rico conjunto de APIs (\textit{Application Programming Interface}) que possibilita ao desenvolvedor criar aplicações robustas, fazendo o uso do GPS, sensores e de todos outros recursos oferecidos pelo dispositivo móvel. Como também, possui um ambiente de desenvolvimento poderoso, inovador e flexível \cite{Lecheta2010}.

\section{Principais Características}
\label{android:caracteristicas}
\indent \indent
A plataforma Android tem como base o SO Linux e com isso herdou algumas das suas características, como, o gerenciamento de \textit{drivers}, segurança, gerenciamento de memória, ser multitarefa (permite que mais de uma aplicação possa ser executada ao mesmo tempo) e \textit{open source}.

O Android possui uma máquina virtual própria, chamada de \textit{Dalvik} (DVM), baseada na JVM (\textit{Java Virtual Machine}), mas, otimizada para consumir pouca memória e poder usar mais de uma instância simultaneamente sem prejudicar o desempenho do dispositivo, no qual cada aplicação roda em um processo próprio e restrito a somente esta aplicação, ou seja, em uma instância da DVM. Antes de serem executados na DVM, aplicativos escritos na linguagem Java e compilados por um compilador Java precisam ser transformados no formato binário .dex. Essa transformação é necessária devido a DVM não operar bytecodes Java, sendo a ferramenta "dx", incluída no SDK, a responsável por essa trasnformação. O arquivo .dex é uma versão melhorada do .class (bytecode java) para dispositivos móveis. Após a conversão, o arquivo é então comprimido em um arquivo com extensão .apk.

O armazenamento na plataforma Android é flexível, podendo ser feito utilizando o banco de dados SQLite (já incluído na SDK) ou qualquer outro, como, por exemplo, MySQL\cite{MySQL} ou PostGreSQL\cite{Postgresql}.

O Android permite que todos os seus componentes nativos possam ser customizados, tais como: a tela inicial, agenda de contatos, entre outros.

O Android está em constante evolução. Atualmente (final de 2012), o Android está na versão (plataforma) 4.0.3, pertence a família 4.x, conhecida como Ice Cream Sandwich. A cada nova versão são acrescentadas novas APIs (\textit{Application Programming Interface}) ou funcionalidades, possibilitando ao desenvolvedor tirar o máximo dos recursos do dispositivo móvel e com isso, possibilitar ao desenvolvedor a criar aplicações robustas.

\section{Arquitetura}
\label{android:arquitetura}
\indent \indent
Um dos pontos fortes da plataforma Android, sem dúvida, é sua arquitetura. Ela estrutura a criação dos aplicativos de forma a manterem um mesmo padrão. Como podemos ver na figura \ref{fig_Arquitetura_Android}, esta arquitetura pode ser dividida em 5 camadas:
\begin{itemize}
	 \item \textit{Applications} (Aplicação);
 	 \item \textit{Application Framework} (Framework de Aplicação);
	 \item \textit{Libraries} (Bibliotecas);
	 \item \textit{Android Runtime};
	 \item \textit{Linux Kernel} (Kernel Linux).
\end{itemize}
	\begin{figure}[h]
		\begin{center}
			\includegraphics{Figuras/Arquitetura_Android.png} 
			\caption{Arquitetura do Android.}
			\label{fig_Arquitetura_Android}
		\end{center}
	\end{figure}
	
Na base da plataforma Android está o Kernel Linux, como mencionado na subseção \ref{android:caracteristicas}. O Android utiliza o Kernel Linux na versão 2.6. Essa camada funciona como um facilitador para o desenvolvedor, servindo como uma abstração entre o hardware do dispositivo e o software que está sendo desenvolvido. Com isso, o desenvolvedor não precisa se preocupar em como será o acesso de sua aplicação aos recursos do hardware do dispositivo, mas sim, em desenvolver as funcionalidades requeridas para a sua aplicação.

Subindo o nível da arquitetura do Android, encontramos a camada Android Runtime e a \textit{Libraries}, juntas formando uma única camada. Podemos dizer que, a camada Android Runtime representa o coração da plataforma Android. Nela se encontra: A DVM (veja a seção \ref{android:caracteristicas}) e \textit{Core Libraries} (responsáveis por gerenciar as funções centrais). E, responsável pela execução das aplicações. Já a camada \textit{Libraries}, possui um conjunto de bibliotecas C ou C++ utilizadas por vários componentes do sistema Android. A capacidade oferecida por essas bibliotecas são expostas ao desenvolvedor pela camada \textit{Application Framework}. Veja abaixo, algumas das bibliotecas disponíveis nessa camada:

\begin{itemize}
	 \item System C library - biblioteca de sistema padrão da linguagem C (libc). Otimizada para dispositivos com Linux embarcado;
	 \item Media Libraries (Framework) - baseada no PacketVideo's OpenCORE. As bibliotecas suportam os mais populares formatos de audio e video, bem como imagens estáticas, incluindo os formatos MPEG4, H.264, MP3, AAC, AMR, JPG, e PNG;
	 \item Surface Manager - gere o acesso ao subsistema de exibição bem como as múltiplas camadas de aplicações 2D e 3D;
	 \item WebKit - um engine de navegador web utilizado tanto no Android Browser quanto para exibições web. Fornece ferramentas para navegar na web;
	 \item SGL - o engine de gráficos 2D;
 	 \item 3D libraries - uma implementação baseada no OpenGL ES 1.0 APIs. Utilizam aceleração 3D via hardware (quando disponível) ou o software de renderização 3D altamente otimizado incluído no Android.	 
     \item FreeType - renderização de fontes vector e bitmaps;
 	 \item SQLite - um poderoso e leve engine de banco de dados relacional, disponível para todas as aplicações.
\end{itemize}

A próxima camada é formada pelo framework de aplicação, comum a todas as aplicações centrais a plataforma. Essa camada possibilita que os desenvolvedores utilizem das mesmas APIs que estas aplicações utilizam. Como também, o reuso de diversos componentes e outras aplicações, tendo que respeitar algumas restrições de segurança impostas pelo próprio framework. O desenvolvedor conversa diretamente com essa camada sempre que precisa criar uma Activity acessando o Activity Manager, por exemplo. Esse é um dos exemplos dos gerenciadores (Manager) que o desenvolvedor pode reutilizar.

E por último, a camada de aplicação. Nessa camada se encontram todas as aplicações, sejam elas: nativas ou criadas pelo desenvolvedor. Dentre as aplicações nativas, podemos citar: cliente de e-mail, programa de SMS, agenda, mapas, navegador, contatos e outras. Sendo, todos os aplicativos implementados na linguagem de programação Java.

	
%\section{Dispositivos Android}
%\label{android:dispositivos}
%\indent \indent
%	\begin{figure}[h]
%		\begin{center}
%			\includegraphics{Figuras/Versoes_do_Android.png} 
%			\caption{Distribuição das versões ou plataformas entre os dispositivos móveis.}
%			\label{fig_versoesAndroid}
%		\end{center}
%	\end{figure}
%	
%	\begin{figure}[h]
%		\begin{center}
%			\includegraphics{Figuras/Android_os_distribution.png} 
%			\caption{Distribuição das versões ou plataformas entre os dispositivos.}
%			\label{fig_distribuicaoAndroid}
%		\end{center}
%	\end{figure}

\section{Aplicações}
\label{android:aplicacoes}
\indent \indent
Esta seção, irá mostrar o "DNA" das aplicações Android, ou seja, do que elas são compostas. Neste ponto da leitura podemos dizer que já conhecemos um pouco dessa plataforma, então chegou a hora de mostrar alguns dos recursos que são disponibilizados ao desenvolvedor para criar uma aplicação.

	\subsection{Ciclo de vida}
	\label{android:aplicacoes:cicloVida}
	\indent \indent
	Conhecer como funciona o ciclo de vida de uma \textit{Activity} (tela ou atividade) é fundamental para criar aplicações mais robustas. Todo o ciclo de vida de uma \textit{Activity} é gerenciado pelo Sistema Operacional Android (SO). Quando o SO necessita de mais recursos acaba interrompendo a execução de alguma \textit{Activity}, liberando assim os recursos que antes estavam sendo utilizados pela mesma. Essa atitude do SO é justificável já que estamos nos referindo a um dispositivo móvel, no qual, os recursos disponíveis são limitados como, capacidade de armazenamento (memória) e poder de processamento, e que para manter um bom funcionamento da aplicação esses recursos têm que ser bem gerenciados.
	
	Uma Activity é basicamente uma classe gerenciadora de UI (User interface). A Activity pode ser usada para, representar uma tela de boas-vindas, um mapa, uma lista de itens, uma tela de opções, ou seja, algo que possa ser apresentável ou visível para o usuário, podendo o mesmo interagir. Nós iremos perceber que todos os aplicativos Android começam por uma Activity.
	
A figura \ref{fig_cicloVidaAtivity} mostra todo o ciclo de vida de uma \textit{Activity} e todos os métodos que são chamados por cada fase do ciclo.
  \begin{figure}[h]
		\begin{center}
			\includegraphics{Figuras/ciclodeVidaActivity3.png} 
			\caption{Ciclo de Vida de uma \textit{Activity}.}
			\label{fig_cicloVidaAtivity}
		\end{center}
	\end{figure}
	
	O método onCreat é o responsável por criar a \textit{Activity} e é executada somente uma única vez, ele pode ser usado para abrir arquivos que serão utilizados pela \textit{Activity}, por exemplo. No momento da chamada do método onStart, já deve existir a \textit{Activity} e seus componentes visuais, então ele tem a função de exibir a \textit{Activity} ao usuário, porém sem oferecer a interação com a mesma. A partir do método onResume que a \textit{Activity} pode interagir com o usuário, ou seja, nesta fase dizemos que a \textit{Activity} está em execução.
	
Já o método onPause é chamado sempre que a \textit{Activity} corrente for interrompida por uma outra \textit{Activity} ficando temporariamente suspensa e salvando o seu estado atual, para que, quando esta voltar a executar, possa recuperar tudo, se necessário, no método onResume. O método onStop é chamado quando a \textit{Activity} corrente está sendo executada em segundo plano ou está  sendo eliminada porque não será mais utilizada; Podendo nessa fase a \textit{Activity} ser reiniciada com a chamada do método onRestart ou finalizada com a chamada do método onDestroy. 
	
É fácil perceber através da imagem \ref{fig_cicloVidaAtivity}, quais são as fases do ciclo em que o SO pode liberar recursos, ou seja, finalizar alguma \textit{Activity} que está muito tempo sem ser executada. E que também, no ciclo da \textit{Activity}, os únicos métodos que não são executados mais de uma vez são os métodos onCreat e o onDestroy.

	
	\subsection{Gerenciadores de \textit{Layout}}
	\label{android:aplicacoes:gerenciadores}
	\indent \indent
	O Layout está presente em todas as aplicações, seja voltada para Web, Desktop ou Dispositivo móvel. O layout serve para criar a estrutura da aplicação, definindo a ordem ou sequência em que os componentes visuais  ,nela contidos, são exibidos na tela. Alguns desses componentes visuais são descritos na seção \ref{android:aplicacoes:componentes}.
	
	A plataforma Android disponibiliza para o desenvolvedor um conjunto de gerenciadores de Layout, são eles: LinearLayout, AbsoluteLayout, TableLayout, RelativeLayout e FrameLayout.
	
	\subsection{Componentes Básicos}
	\label{android:aplicacoes:componentes}
	\indent \indent
O framework Android conta com um novo conceito chamado de \textit{Intent}. A classe android.content.Intent representa uma "ação" que a aplicação deseja executar. Com a \textit{Intent} é possível invocar componentes  e a comunicação entre processos. A \textit{Intent} está presente em todos os lugares e representa uma mensagem da aplicação para o sistema operacional Android, solicitando que algo seja realizado (ação)  \cite{Lecheta2010}. Por exemplo, ao navegar nas telas do celular, para o usuário é transparente, mas várias \textit{Intents} estão sendo criadas para solicitar ao SO que execute determinada tarefa.

Segundo \cite{Lecheta2010}, a \textit{Intent} pode ser utilizada para:

\begin{itemize}
	 \item Enviar uma mensagem para o sistema operacional;
 	 \item Abrir uma nova tela da aplicação, utilizando o método startActivity;
	 \item Solicitar ao sistema operacional que ligue para determinado número de celular;
	 \item Abrir o browser em um determinado endereço da \textit{Intent};
	 \item Exibir algum endereço, localização ou rota no Google Maps;
	 \item Executar algum processamento pesado em segundo plano usando as classe BroadcastIntentReceiver e Service;
	 \item Enviar uma mensagem para outra aplicação para executar outro processo;
	 \item Abrir o Android Market para fazer a instalação de determinado aplicativo;

\end{itemize}

O SO fica encarregado de tomar as decisões de acordo com o conteúdo da mensagem. Essa mensagem é chamada de \textit{broadcast}. E para que o SO tome decisões, é preciso que tenha em algum lugar a ação que deve ser executada para cada categoria de mensagem.  Para essa finalidade tem-se a classe android.content.IntentFilter. Essa classe permite mapear uma ação para determinada tarefa. Com isso, somente a \textit{Activity} que esteja mapeada para aquela ação será executada. Abaixo, nos códigos \ref{intentFilter} e \ref{intent}, segue um exemplo do mapeamento de uma ação para uma \textit{Activity}.

	%% Adicionando Código	
\lstset{frame=single, captionpos=b,morecomment=[s][\color{blue}]{<}{>}}
\lstinputlisting[frame=single, label=intentFilter, caption={"Exemplo do IntentFilter."}]
{ArquivoFonte/IntentFilter.xml}	

\lstset{frame=single, captionpos=b,morecomment=[s][\color{blue}]{<}{>}}
\lstinputlisting[frame=single, label=intent, caption={"Exemplo do uso do Intent no envio de uma mensagem ao SO."}]
{ArquivoFonte/intent.xml}

Como visto na seção \ref{android:aplicacoes:cicloVida}, todas as \textit{Activitys} são definidas dentro do arquivo androidManifest. Com isso, o \textit{IntentFilter}  também é definido  nesse arquivo.  É importante perceber que, o filtro de intenções (\textit{IntentFilter}) usa duas tags \flq action\frq \ e \flq category\frq \ para identificar o que deverá ser executado.
		
	"A classe View é responsável por desenhar algo na tela e tratar seus eventos se necessários, e é a classe-base para todos os componentes visuais Android" \cite{Lecheta2010}. Aqui será mostrado alguns desses componentes visuais, tais como, TextView, EditText, Button, CheckBox,  RadioButton e RadioGroup. No Android, todos os elementos da aplicação são representados por tags. E toda tag deve ser aberta e fechada, representada respectivamente por \flq nome\frq \ e \flq /nome\frq. Na figura \ref{fig_Activity_simples}, é possível ver um exemplo do uso desses componentes.
	
	A tag \flq TextView\frq \ serve unicamente para a exibição de texto na tela de sua aplicação Android. Em outras plataformas, é conhecido como label. Veja um exemplo no código \ref{textView}.

	O componente EditText é uma especialização do componente TextView. E representa um campo texto, no qual o usuário pode digitar. Esse componente é referenciado no arquivo pela tag \flq EditText\frq. Veja um exemplo no código \ref{EditText}.

	O componente Button representa um botão. É referenciado no arquivo .xml pela tag \flq Button\frq. Veja um exemplo no código \ref{Button}.
		
	O componente CheckBox, representa um tipo especial de botão, que só assume dois valores: \textit{true} (marcado) ou \textit{false} (desmarcado). É referenciado no arquivo .xml pela tag \flq CheckBox\frq. Veja um exemplo no código \ref{CheckBox}.
	
	Assim como o CheckBox, o RadioButton também só assume dois valores: \textit{true} (marcado) ou \textit{false} (desmarcado). Além da sua forma, outra diferença é que o RadioButton uma vez marcado não poderá mais ser desmarcado. É referenciado no arquivo .xml pela tag \flq RadioButton\frq. Veja um exemplo no código \ref{RadioGroup}.
	
	O componente RadioGroup serve para agrupar um ou mais RadioButton. Permitindo asssim que, apenas um RadioButton seja verificado (marcado). O RadioGroup é referenciado no arquivo .xml pela tag \flq RadioGroup\frq. Veja um exemplo no código \ref{RadioGroup}.
	\newline

	\begin{figure}[h]
		\begin{center}
			\includegraphics{Figuras/Exemplo_de_uma_Activity.png} 
			\caption{Exemplo de uma Activity.}
			\label{fig_Activity_simples}
		\end{center}
	\end{figure}
	
	%% Adicionando Código	
\lstset{frame=single, captionpos=b,morecomment=[s][\color{blue}]{<}{>}}
\lstinputlisting[frame=single, label=textView, caption={"Exemplo do xml para o componente TextView."}]
{ArquivoFonte/TextView.xml}

\lstset{frame=single, captionpos=b,morecomment=[s][\color{blue}]{<}{>}}
\lstinputlisting[frame=single, label=EditText, caption={"Exemplo do xml para o componente EditText."}]
{ArquivoFonte/Editext.xml}

\lstset{frame=single, captionpos=b,morecomment=[s][\color{blue}]{<}{>}}
\lstinputlisting[frame=single, label=Button, caption={"Exemplo do xml para o componente Button."}]
{ArquivoFonte/Button.xml}

\lstset{frame=single, captionpos=b,morecomment=[s][\color{blue}]{<}{>}}
\lstinputlisting[frame=single, label=CheckBox, caption={"Exemplo do xml para o componente CheckBox."}]
{ArquivoFonte/CheckBox.xml}

\lstset{frame=single, captionpos=b,morecomment=[s][\color{blue}]{<}{>}}
\lstinputlisting[frame=single, label=RadioGroup, caption={"Exemplo do xml para os componentes RadioGroup e RadioButton."}]
{ArquivoFonte/RadioGroup.xml}

% fim do código

	\subsection{Classe R}
	\label{android:aplicacoes:classeR} 
	\indent \indent
	É uma classe JAVA que, ao criar um novo projeto, é gerada automaticamente pela ferramenta de desenvolvimento (plugin ADT ou MOTODEV) e gerenciada pela mesma. A classe R nunca deve ser alterada manualmente. Sua atualização acontece quando um novo arquivo, não importando o seu tipo, é adicionado em alguma das seguintes pastas: drawable, layout e values. Essas pastas contêm respectivamente, imagens, arquivos XML que representam as telas da aplicação e arquivos XML que contém as mensagens da aplicação. Então, ao adicionar um novo recurso em uma dessas pastas, é gerada automaticamente uma nova constante na classe R.
	
Como podemos perceber, a classe R serve de acesso aos recursos do projeto, pois, nela são guardadas constantes, do tipo int e de valor único dentro do projeto, que são utilizadas para referenciar algum recurso do projeto, que pode ser: uma imagem, botão ou um arquivo XML que define alguma tela da aplicação.

O acesso aos recursos do projeto usando a classe R funciona da seguinte maneira. Por padrão a nova constante recebe o nome da pasta que contém o recurso, mais o nome do arquivo sem sua extensão. Nesse caso teríamos que, para acessar a imagem "android.png" que está na pasta drawable, faríamos R. drawable.android. E caso queira usar a classe R para acessar algum recurso, o nome da pasta e do arquivo devem estar em minúsculo e não devem conter espaços.

	\subsection{ Arquivo AndroidManifest}
	\label{android:aplicacoes:arquivoManifest}
	\indent \indent
	O Arquivo AndroidManifest é a base de toda aplicação Android. Ele é um arquivo de configuração, obrigatório em todo o projeto Android, contendo permissões de acesso ao Hardware, como, sensores e câmera, assim como o acesso a internet. Além disso, é necessário que toda Activity do projeto esteja declarada nesse arquivo, caso contrário não será possível utilizá-la.
\newline
	
\lstset{frame=single, captionpos=b,morecomment=[s][\color{blue}]{<}{>}}
\lstinputlisting[frame=single, label=fig_exAndroidManifest, caption={"Exemplo de um Arquivo AndroidManifest."}]
{ArquivoFonte/manifest.xml}
	
No código \ref{fig_exAndroidManifest} é mostrado um exemplo de Arquivo AndroidManifest.xml, em que é pedido a permissão para a aplicação ter acesso a internet.

Como podemos perceber no código \ref{fig_exAndroidManifest}, a tag \flq manifest\frq \ tem como atributo o nome do pacote (package), código da versão (android:versionCode) e nome da versão (versionName)  e dentro dela fica toda a configuração da aplicação. Na linha 7, temos a permissão para acessar a localização via GPS. Dentro da tag \flq application\frq \ irá ficar todas as Activitys que fazem parte da aplicação.

Lembrando que, o conteúdo do arquivo AndroidManifest.xml, dependerá de cada aplicação Android.

%\section{Recursos Avançados do Android}
%\label{android:aplicacoes:recursosAvancados}
%\indent \indent
	
\section{Ferramentas}
\label{android:ferramentas}
\indent \indent
As ferramentas de programação ou IDEs são úteis para auxiliar o desenvolvedor em suas tarefas, proporcionando aumento da produtividade, reduzindo o tempo de desenvolvimento. 
Para o desenvolvimento de aplicações para o ambiente Android tem-se o plugin ADT e o MOTODEV Studio. O plugin ADT é instalado na IDE Eclipse e toda sua configuração é feita manualmente. 

O MOTODEV Studio é uma IDE alternativa para o desenvolvimento de aplicações para o ambiente Android. Essa IDE é uma versão modificada do Eclipse criada pela Motorola. O MOTODEV Studio já vem configurado, pronto para o desenvolvedor começar a criar suas aplicações e oferece recursos adicionais que agiliza o desenvolvimento.

%O item (\emph{...}) da proposição (\ref{...}) nos permite,



% chamando uma referência
%  ~\cite{RA}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Minhas referências.  
\bibliography{refBib}  
\bibliographystyle{plain} 
\end{document}
